var documenterSearchIndex = {"docs":
[{"location":"api/#Stats","page":"API","title":"Stats","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Pages = [\"stats.md\"]","category":"page"},{"location":"api/#Summary-statistics","page":"API","title":"Summary statistics","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"SummaryStats\nsummarystats","category":"page"},{"location":"api/#PosteriorStats.SummaryStats","page":"API","title":"PosteriorStats.SummaryStats","text":"A container for a column table of values computed by summarystats.\n\nThis object implements the Tables and TableTraits interfaces and has a custom show method.\n\ndata: The summary statistics for each variable, with the first entry containing the variable names\n\n\n\n\n\n","category":"type"},{"location":"api/#StatsBase.summarystats","page":"API","title":"StatsBase.summarystats","text":"summarystats(data::InferenceData; group=:posterior, kwargs...)\nsummarystats(data::Dataset; kwargs...)\n\nCompute summary statistics and diagnostics on the data.\n\nKeywords\n\nprob_interval::Real: The value of the prob argument to hdi used to compute the highest density interval. Defaults to 0.94.\nreturn_type::Type: The type of object to return. Valid options are Dataset and SummaryStats. Defaults to SummaryStats.\nmetric_dim: The dimension name or type to use for the computed metrics. Only used if return_type is Dataset. Defaults to Dim{:_metric}.\ncompact_labels::Bool: Whether to use compact names for the variables. Only used if return_type is SummaryStats. Defaults to true.\nkind::Symbol: Whether to compute just statistics (:stats), just diagnostics (:diagnostics), or both (:both). Defaults to :both.\n\nExamples\n\nCompute the summary statistics and diagnostics on posterior draws of the centered eight model:\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> summarystats(idata.posterior[(:mu, :tau)])\nSummaryStats\n      mean  std  hdi_3%  hdi_97%  mcse_mean  mcse_std  ess_tail  ess_bulk  rha ⋯\n mu    4.5  3.5  -1.62     10.7        0.23      0.11       659       241  1.0 ⋯\n tau   4.1  3.1   0.896     9.67       0.26      0.17        38        67  1.0 ⋯\n                                                                1 column omitted\n\nCompute just the statistics on all variables:\n\njulia> summarystats(idata.posterior; kind=:stats)\nSummaryStats\n                          mean   std  hdi_3%  hdi_97%\n mu                       4.49  3.49  -1.62     10.7\n theta[Choate]            6.46  5.87  -4.56     17.1\n theta[Deerfield]         5.03  4.88  -4.31     14.3\n theta[Phillips Andover]  3.94  5.69  -7.77     13.7\n theta[Phillips Exeter]   4.87  5.01  -4.49     14.7\n theta[Hotchkiss]         3.67  4.96  -6.47     11.7\n theta[Lawrenceville]     3.97  5.19  -7.04     12.2\n theta[St. Paul's]        6.58  5.11  -3.09     16.3\n theta[Mt. Hermon]        4.77  5.74  -5.86     16.0\n tau                      4.12  3.10   0.896     9.67\n\nCompute the statistics and diagnostics from the posterior group of an InferenceData and store in a Dataset:\n\njulia> using InferenceObjects\n\njulia> summarystats(idata; return_type=Dataset)\nDataset with dimensions:\n  Dim{:_metric} Categorical{String} String[mean, std, …, ess_bulk, rhat] Unordered,\n  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul's, Mt. Hermon] Unordered\nand 3 layers:\n  :mu    Float64 dims: Dim{:_metric} (9)\n  :theta Float64 dims: Dim{:school}, Dim{:_metric} (8×9)\n  :tau   Float64 dims: Dim{:_metric} (9)\n\n\n\n\n\n","category":"function"},{"location":"api/#General-statistics","page":"API","title":"General statistics","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"hdi\nhdi!\nr2_score","category":"page"},{"location":"api/#PosteriorStats.hdi","page":"API","title":"PosteriorStats.hdi","text":"hdi(samples::AbstractArray{<:Real}; prob=0.94) -> (; lower, upper)\n\nEstimate the unimodal highest density interval (HDI) of samples for the probability prob.\n\nThe HDI is the minimum width Bayesian credible interval (BCI). That is, it is the smallest possible interval containing at least (100*prob)% of the draws.[Hyndman1996]\n\nsamples is an array of shape (draws[, chains[, params...]]). If multiple parameters are present, then lower and upper are arrays with the shape (params...,), computed separately for each marginal.\n\nThis implementation uses the algorithm of [ChenShao1999].\n\nnote: Note\nAny default value of prob is arbitrary. The default value of prob=0.94 instead of a more common default like prob=0.95 is chosen to reminder the user of this arbitrariness.\n\n[Hyndman1996]: Rob J. Hyndman (1996) Computing and Graphing Highest Density Regions,             Amer. Stat., 50(2): 120-6.             DOI: 10.1080/00031305.1996.10474359             jstor.\n\n[ChenShao1999]: Ming-Hui Chen & Qi-Man Shao (1999)              Monte Carlo Estimation of Bayesian Credible and HPD Intervals,              J Comput. Graph. Stat., 8:1, 69-92.              DOI: 10.1080/10618600.1999.10474802              jstor.\n\nExamples\n\nHere we calculate the 83% HDI for a normal random variable:\n\njulia> using PosteriorStats\n\njulia> x = randn(2_000);\n\njulia> hdi(x; prob=0.83) |> pairs\npairs(::NamedTuple) with 2 entries:\n  :lower => -1.38266\n  :upper => 1.25982\n\nWe can also calculate the HDI for a 3-dimensional array of samples:\n\njulia> x = randn(1_000, 1, 1) .+ reshape(0:5:10, 1, 1, :);\n\njulia> hdi(x) |> pairs\npairs(::NamedTuple) with 2 entries:\n  :lower => [-1.9674, 3.0326, 8.0326]\n  :upper => [1.90028, 6.90028, 11.9003]\n\n\n\n\n\nhdi(data::InferenceData; prob=0.94) -> Dataset\nhdi(data::Dataset; prob=0.94) -> Dataset\n\nCalculate the highest density interval (HDI) for each parameter in the data.\n\nExamples\n\nCalculate HDI for all parameters in the posterior group of an InferenceData:\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> hdi(idata)\nDataset with dimensions:\n  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul's, Mt. Hermon] Unordered,\n  Dim{:hdi_bound} Categorical{Symbol} Symbol[:lower, :upper] ForwardOrdered\nand 3 layers:\n  :mu    Float64 dims: Dim{:hdi_bound} (2)\n  :theta Float64 dims: Dim{:school}, Dim{:hdi_bound} (8×2)\n  :tau   Float64 dims: Dim{:hdi_bound} (2)\n\nWe can also calculate the HDI for a subset of variables:\n\njulia> hdi(idata.posterior[(:theta,)]).theta\n8×2 DimArray{Float64,2} theta with dimensions:\n  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul's, Mt. Hermon] Unordered,\n  Dim{:hdi_bound} Categorical{Symbol} Symbol[:lower, :upper] ForwardOrdered\n                        :lower    :upper\n  \"Choate\"            -4.56375  17.1324\n  \"Deerfield\"         -4.31055  14.2535\n  \"Phillips Andover\"  -7.76922  13.6755\n  \"Phillips Exeter\"   -4.48955  14.6635\n  \"Hotchkiss\"         -6.46991  11.7191\n  \"Lawrenceville\"     -7.04111  12.2087\n  \"St. Paul's\"        -3.09262  16.2685\n  \"Mt. Hermon\"        -5.85834  16.0143\n\n\n\n\n\n","category":"function"},{"location":"api/#PosteriorStats.hdi!","page":"API","title":"PosteriorStats.hdi!","text":"hdi!(samples::AbstractArray{<:Real}; prob=0.94) -> (; lower, upper)\n\nA version of hdi that sorts samples in-place while computing the HDI.\n\n\n\n\n\n","category":"function"},{"location":"api/#PosteriorStats.r2_score","page":"API","title":"PosteriorStats.r2_score","text":"r2_score(y_true::AbstractVector, y_pred::AbstractVecOrMat) -> (; r2, r2_std)\n\nR² for linear Bayesian regression models.[GelmanGoodrich2019]\n\nArguments\n\ny_true: Observed data of length noutputs\ny_pred: Predicted data with size (ndraws[, nchains], noutputs)\n\n[GelmanGoodrich2019]: Andrew Gelman, Ben Goodrich, Jonah Gabry & Aki Vehtari (2019) R-squared for Bayesian Regression Models, The American Statistician, 73:3, 307-9, DOI: 10.1080/00031305.2018.1549100.\n\nExamples\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"regression1d\");\n\njulia> y_true = idata.observed_data.y;\n\njulia> y_pred = PermutedDimsArray(idata.posterior_predictive.y, (:draw, :chain, :y_dim_0));\n\njulia> r2_score(y_true, y_pred) |> pairs\npairs(::NamedTuple) with 2 entries:\n  :r2     => 0.683197\n  :r2_std => 0.0368838\n\n\n\n\n\nr2_score(idata::InferenceData; y_name, y_pred_name) -> (; r2, r2_std)\n\nCompute R² from idata, automatically formatting the predictions to the correct shape.\n\nKeywords\n\ny_name: Name of observed data variable in idata.observed_data. If not provided, then the only observed data variable is used.\ny_pred_name: Name of posterior predictive variable in idata.posterior_predictive. If not provided, then y_name is used.\n\nExamples\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"regression10d\");\n\njulia> r2_score(idata) |> pairs\npairs(::NamedTuple) with 2 entries:\n  :r2     => 0.998385\n  :r2_std => 0.000100621\n\n\n\n\n\n","category":"function"},{"location":"api/#LOO-and-WAIC","page":"API","title":"LOO and WAIC","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AbstractELPDResult\nPSISLOOResult\nWAICResult\nelpd_estimates\ninformation_criterion\nloo\nwaic","category":"page"},{"location":"api/#PosteriorStats.AbstractELPDResult","page":"API","title":"PosteriorStats.AbstractELPDResult","text":"abstract type AbstractELPDResult\n\nAn abstract type representing the result of an ELPD computation.\n\nEvery subtype stores estimates of both the expected log predictive density (elpd) and the effective number of parameters p, as well as standard errors and pointwise estimates of each, from which other relevant estimates can be computed.\n\nSubtypes implement the following functions:\n\nelpd_estimates\ninformation_criterion\n\n\n\n\n\n","category":"type"},{"location":"api/#PosteriorStats.PSISLOOResult","page":"API","title":"PosteriorStats.PSISLOOResult","text":"Results of Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO).\n\nSee also: loo, AbstractELPDResult\n\nestimates: Estimates of the expected log pointwise predictive density (ELPD) and effective number of parameters (p)\npointwise: Pointwise estimates\npsis_result: Pareto-smoothed importance sampling (PSIS) results\n\n\n\n\n\n","category":"type"},{"location":"api/#PosteriorStats.WAICResult","page":"API","title":"PosteriorStats.WAICResult","text":"Results of computing the widely applicable information criterion (WAIC).\n\nSee also: waic, AbstractELPDResult\n\nestimates: Estimates of the expected log pointwise predictive density (ELPD) and effective number of parameters (p)\npointwise: Pointwise estimates\n\n\n\n\n\n","category":"type"},{"location":"api/#PosteriorStats.elpd_estimates","page":"API","title":"PosteriorStats.elpd_estimates","text":"elpd_estimates(result::AbstractELPDResult; pointwise=false) -> (; elpd, elpd_mcse, lpd)\n\nReturn the (E)LPD estimates from the result.\n\n\n\n\n\n","category":"function"},{"location":"api/#PosteriorStats.information_criterion","page":"API","title":"PosteriorStats.information_criterion","text":"information_criterion(elpd, scale::Symbol)\n\nCompute the information criterion for the given scale from the elpd estimate.\n\nscale must be one of (:deviance, :log, :negative_log).\n\nSee also: loo, waic\n\n\n\n\n\ninformation_criterion(result::AbstractELPDResult, scale::Symbol; pointwise=false)\n\nCompute information criterion for the given scale from the existing ELPD result.\n\nscale must be one of (:deviance, :log, :negative_log).\n\nIf pointwise=true, then pointwise estimates are returned.\n\n\n\n\n\n","category":"function"},{"location":"api/#PosteriorStats.loo","page":"API","title":"PosteriorStats.loo","text":"loo(log_likelihood; reff=nothing, kwargs...) -> PSISLOOResult{<:NamedTuple,<:NamedTuple}\n\nCompute the Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO). [Vehtari2017][LOOFAQ]\n\nlog_likelihood must be an array of log-likelihood values with shape (chains, draws[, params...]).\n\nKeywords\n\nreff::Union{Real,AbstractArray{<:Real}}: The relative effective sample size(s) of the likelihood values. If an array, it must have the same data dimensions as the corresponding log-likelihood variable. If not provided, then this is estimated using MCMCDiagnosticTools.ess.\nkwargs: Remaining keywords are forwarded to [PSIS.psis].\n\nSee also: PSISLOOResult, waic\n\n[Vehtari2017]: Vehtari, A., Gelman, A. & Gabry, J. Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Stat Comput 27, 1413–1432 (2017). doi: 10.1007/s11222-016-9696-4 arXiv: 1507.04544\n\n[LOOFAQ]: Aki Vehtari. Cross-validation FAQ. https://mc-stan.org/loo/articles/online-only/faq.html\n\nExamples\n\nManually compute R_mathrmeff and calculate PSIS-LOO of a model:\n\njulia> using ArviZExampleData, MCMCDiagnosticTools, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> log_like = PermutedDimsArray(idata.log_likelihood.obs, (:draw, :chain, :school));\n\njulia> reff = ess(log_like; kind=:basic, split_chains=1, relative=true);\n\njulia> loo(log_like; reff)\nPSISLOOResult with estimates\n elpd  elpd_mcse    p  p_mcse\n  -31        1.4  0.9    0.34\n\nand PSISResult with 500 draws, 4 chains, and 8 parameters\nPareto shape (k) diagnostic values:\n                    Count      Min. ESS\n (-Inf, 0.5]  good  7 (87.5%)  151\n  (0.5, 0.7]  okay  1 (12.5%)  446\n\n\n\n\n\nloo(data::Dataset; [var_name::Symbol,] kwargs...) -> PSISLOOResult{<:NamedTuple,<:Dataset}\nloo(data::InferenceData; [var_name::Symbol,] kwargs...) -> PSISLOOResult{<:NamedTuple,<:Dataset}\n\nCompute PSIS-LOO from log-likelihood values in data.\n\nIf more than one log-likelihood variable is present, then var_name must be provided.\n\nExamples\n\nCalculate PSIS-LOO of a model:\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> loo(idata)\nPSISLOOResult with estimates\n elpd  elpd_mcse    p  p_mcse\n  -31        1.4  0.9    0.34\n\nand PSISResult with 500 draws, 4 chains, and 8 parameters\nPareto shape (k) diagnostic values:\n                    Count      Min. ESS\n (-Inf, 0.5]  good  6 (75.0%)  135\n  (0.5, 0.7]  okay  2 (25.0%)  421\n\n\n\n\n\n","category":"function"},{"location":"api/#PosteriorStats.waic","page":"API","title":"PosteriorStats.waic","text":"waic(log_likelihood::AbstractArray) -> WAICResult{<:NamedTuple,<:NamedTuple}\n\nCompute the widely applicable information criterion (WAIC).[Watanabe2010][Vehtari2017][LOOFAQ]\n\nlog_likelihood must be an array of log-likelihood values with shape (chains, draws[, params...]).\n\nSee also: WAICResult, loo\n\n[Watanabe2010]: Watanabe, S. Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory. 11(116):3571−3594, 2010. https://jmlr.csail.mit.edu/papers/v11/watanabe10a.html\n\n[Vehtari2017]: Vehtari, A., Gelman, A. & Gabry, J. Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Stat Comput 27, 1413–1432 (2017). doi: 10.1007/s11222-016-9696-4 arXiv: 1507.04544\n\n[LOOFAQ]: Aki Vehtari. Cross-validation FAQ. https://mc-stan.org/loo/articles/online-only/faq.html\n\nExamples\n\nCalculate WAIC of a model:\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> log_like = PermutedDimsArray(idata.log_likelihood.obs, (:draw, :chain, :school));\n\njulia> waic(log_like)\nWAICResult with estimates\n elpd  elpd_mcse    p  p_mcse\n  -31        1.4  0.9    0.33\n\n\n\n\n\nwaic(data::Dataset; [var_name::Symbol]) -> WAICResult{<:NamedTuple,<:Dataset}\nwaic(data::InferenceData; [var_name::Symbol]) -> WAICResult{<:NamedTuple,<:Dataset}\n\nCompute WAIC from log-likelihood values in data.\n\nIf more than one log-likelihood variable is present, then var_name must be provided.\n\nExamples\n\nCalculate WAIC of a model:\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> waic(idata)\nWAICResult with estimates\n elpd  elpd_mcse    p  p_mcse\n  -31        1.4  0.9    0.33\n\n\n\n\n\n","category":"function"},{"location":"api/#Model-comparison","page":"API","title":"Model comparison","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ModelComparisonResult\ncompare\nmodel_weights","category":"page"},{"location":"api/#PosteriorStats.ModelComparisonResult","page":"API","title":"PosteriorStats.ModelComparisonResult","text":"ModelComparisonResult\n\nResult of model comparison using ELPD.\n\nThis struct implements the Tables and TableTraits interfaces.\n\nEach field returns a collection of the corresponding entry for each model:\n\nname: Names of the models, if provided.\nrank: Ranks of the models (ordered by decreasing ELPD)\nelpd_diff: ELPD of a model subtracted from the largest ELPD of any model\nelpd_diff_mcse: Monte Carlo standard error of the ELPD difference\nweight: Model weights computed with weights_method\nelpd_result: AbstactELPDResults for each model, which can be used to access useful stats like ELPD estimates, pointwise estimates, and Pareto shape values for PSIS-LOO\nweights_method: Method used to compute model weights with model_weights\n\n\n\n\n\n","category":"type"},{"location":"api/#PosteriorStats.compare","page":"API","title":"PosteriorStats.compare","text":"compare(models; kwargs...)\n\nCompare models based on their expected log pointwise predictive density (ELPD).\n\nmodels is a Tuple, NamedTuple, or AbstractVector whose values are either AbstractELPDResult entries or any argument to elpd_method, which must produce an AbstractELPDResult.\n\nThe weights are returned in the same type of collection.\n\nThe argument may be any object with a pairs method where each value is either an InferenceData or an AbstractELPDResult.\n\nThe ELPD is estimated either by Pareto smoothed importance sampling leave-one-out cross-validation (LOO) or using the widely applicable information criterion (WAIC). We recommend loo. Read more theory here - in a paper by some of the leading authorities on model comparison dx.doi.org/10.1111/1467-9868.00353\n\nArguments\n\nmodels: a Tuple, NamedTuple, or AbstractVector whose values are either AbstractELPDResult entries or any argument to elpd_method.\n\nKeywords\n\nweights_method::AbstractModelWeightsMethod=Stacking(): the method to be used to weight the models. See model_weights for details\nelpd_method=loo: a method that computes an AbstractELPDResult from an argument in models.\nsort::Bool=true: Whether to sort models by decreasing ELPD.\n\nReturns\n\nModelComparisonResult: A container for the model comparison results.\n\nExamples\n\nCompare the centered and non centered models of the eight school problem using the defaults: loo and Stacking weights:\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> models = (\n           centered=load_example_data(\"centered_eight\"),\n           non_centered=load_example_data(\"non_centered_eight\"),\n       );\n\njulia> mc = compare(models)\n┌ Warning: 1 parameters had Pareto shape values 0.7 < k ≤ 1. Resulting importance sampling estimates are likely to be unstable.\n└ @ PSIS ~/.julia/packages/PSIS/...\nModelComparisonResult with Stacking weights\n               rank  elpd  elpd_mcse  elpd_diff  elpd_diff_mcse  weight    p   ⋯\n non_centered     1   -31        1.4       0              0.0       1.0  0.9   ⋯\n centered         2   -31        1.4       0.06           0.067     0.0  0.9   ⋯\n                                                                1 column omitted\n\nCompare the same models from pre-computed PSIS-LOO results and computing BootstrappedPseudoBMA weights:\n\njulia> elpd_results = mc.elpd_result;\n\njulia> compare(elpd_results; weights_method=BootstrappedPseudoBMA())\nModelComparisonResult with BootstrappedPseudoBMA weights\n               rank  elpd  elpd_mcse  elpd_diff  elpd_diff_mcse  weight    p   ⋯\n non_centered     1   -31        1.4       0              0.0      0.52  0.9   ⋯\n centered         2   -31        1.4       0.06           0.067    0.48  0.9   ⋯\n                                                                1 column omitted\n\n\n\n\n\n","category":"function"},{"location":"api/#PosteriorStats.model_weights","page":"API","title":"PosteriorStats.model_weights","text":"model_weights(elpd_results; method=Stacking())\nmodel_weights(method::AbstractModelWeightsMethod, elpd_results)\n\nCompute weights for each model in elpd_results using method.\n\nelpd_results is a Tuple, NamedTuple, or AbstractVector with AbstractELPDResult entries. The weights are returned in the same type of collection.\n\nStacking is the recommended approach, as it performs well even when the true data generating process is not included among the candidate models. See [YaoVehtari2018] for details.\n\nSee also: AbstractModelWeightsMethod, compare\n\n[YaoVehtari2018]: Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Using Stacking to Average Bayesian Predictive Distributions.Bayesian Analysis. 13, 3, 917–1007.doi: 10.1214/17-BA1091 arXiv: 1704.02030\n\nExamples\n\nCompute Stacking weights for two models:\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> models = (\n           centered=load_example_data(\"centered_eight\"),\n           non_centered=load_example_data(\"non_centered_eight\"),\n       );\n\njulia> elpd_results = map(loo, models);\n┌ Warning: 1 parameters had Pareto shape values 0.7 < k ≤ 1. Resulting importance sampling estimates are likely to be unstable.\n└ @ PSIS ~/.julia/packages/PSIS/...\n\njulia> model_weights(elpd_results; method=Stacking()) |> pairs\npairs(::NamedTuple) with 2 entries:\n  :centered     => 5.34175e-19\n  :non_centered => 1.0\n\nNow we compute BootstrappedPseudoBMA weights for the same models:\n\njulia> model_weights(elpd_results; method=BootstrappedPseudoBMA()) |> pairs\npairs(::NamedTuple) with 2 entries:\n  :centered     => 0.483723\n  :non_centered => 0.516277\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"The following model weighting methods are available","category":"page"},{"location":"api/","page":"API","title":"API","text":"AbstractModelWeightsMethod\nBootstrappedPseudoBMA\nPseudoBMA\nStacking","category":"page"},{"location":"api/#PosteriorStats.AbstractModelWeightsMethod","page":"API","title":"PosteriorStats.AbstractModelWeightsMethod","text":"abstract type AbstractModelWeightsMethod\n\nAn abstract type representing methods for computing model weights.\n\nSubtypes implement model_weights(method, elpd_results).\n\n\n\n\n\n","category":"type"},{"location":"api/#PosteriorStats.BootstrappedPseudoBMA","page":"API","title":"PosteriorStats.BootstrappedPseudoBMA","text":"struct BootstrappedPseudoBMA{R<:Random.AbstractRNG, T<:Real} <: AbstractModelWeightsMethod\n\nModel weighting method using pseudo Bayesian Model Averaging using Akaike-type weighting with the Bayesian bootstrap (pseudo-BMA+)[YaoVehtari2018].\n\nThe Bayesian bootstrap stabilizes the model weights.\n\nBootstrappedPseudoBMA(; rng=Random.default_rng(), samples=1_000, alpha=1)\nBootstrappedPseudoBMA(rng, samples, alpha)\n\nConstruct the method.\n\nrng::Random.AbstractRNG: The random number generator to use for the Bayesian bootstrap\nsamples::Int64: The number of samples to draw for bootstrapping\nalpha::Real: The shape parameter in the Dirichlet distribution used for the Bayesian bootstrap. The default (1) corresponds to a uniform distribution on the simplex.\n\nSee also: Stacking\n\n[YaoVehtari2018]: Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Using Stacking to Average Bayesian Predictive Distributions.Bayesian Analysis. 13, 3, 917–1007.doi: 10.1214/17-BA1091 arXiv: 1704.02030\n\n\n\n\n\n","category":"type"},{"location":"api/#PosteriorStats.PseudoBMA","page":"API","title":"PosteriorStats.PseudoBMA","text":"struct PseudoBMA <: AbstractModelWeightsMethod\n\nModel weighting method using pseudo Bayesian Model Averaging (pseudo-BMA) and Akaike-type weighting.\n\nPseudoBMA(; regularize=false)\nPseudoBMA(regularize)\n\nConstruct the method with optional regularization of the weights using the standard error of the ELPD estimate.\n\nnote: Note\nThis approach is not recommended, as it produces unstable weight estimates. It is recommended to instead use BootstrappedPseudoBMA to stabilize the weights or Stacking. For details, see [YaoVehtari2018].\n\n[YaoVehtari2018]: Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Using Stacking to Average Bayesian Predictive Distributions.Bayesian Analysis. 13, 3, 917–1007.doi: 10.1214/17-BA1091 arXiv: 1704.02030\n\nSee also: Stacking\n\n\n\n\n\n","category":"type"},{"location":"api/#PosteriorStats.Stacking","page":"API","title":"PosteriorStats.Stacking","text":"struct Stacking{O<:Optim.AbstractOptimizer} <: AbstractModelWeightsMethod\n\nModel weighting using stacking of predictive distributions[YaoVehtari2018].\n\nStacking(; optimizer=Optim.LBFGS(), options=Optim.Options()\nStacking(optimizer[, options])\n\nConstruct the method, optionally customizing the optimization.\n\noptimizer::Optim.AbstractOptimizer: The optimizer to use for the optimization of the weights. The optimizer must support projected gradient optimization viae a manifold field.\noptions::Optim.Options: The Optim options to use for the optimization of the weights.\n\nSee also: BootstrappedPseudoBMA\n\n[YaoVehtari2018]: Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Using Stacking to Average Bayesian Predictive Distributions.Bayesian Analysis. 13, 3, 917–1007.doi: 10.1214/17-BA1091 arXiv: 1704.02030\n\n\n\n\n\n","category":"type"},{"location":"api/#Predictive-checks","page":"API","title":"Predictive checks","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"loo_pit","category":"page"},{"location":"api/#PosteriorStats.loo_pit","page":"API","title":"PosteriorStats.loo_pit","text":"loo_pit(y, y_pred, log_weights; kwargs...) -> Union{Real,AbstractArray}\n\nCompute leave-one-out probability integral transform (LOO-PIT) checks.\n\nArguments\n\ny: array of observations with shape (params...,)\ny_pred: array of posterior predictive samples with shape (draws, chains, params...).\nlog_weights: array of normalized log LOO importance weights with shape (draws, chains, params...).\n\nKeywords\n\nis_discrete: If not provided, then it is set to true iff elements of y and y_pred are all integer-valued. If true, then data are smoothed using smooth_data to make them non-discrete before estimating LOO-PIT values.\nkwargs: Remaining keywords are forwarded to smooth_data if data is discrete.\n\nReturns\n\npitvals: LOO-PIT values with same size as y. If y is a scalar, then pitvals is a scalar.\n\nLOO-PIT is a marginal posterior predictive check. If y_-i is the array y of observations with the ith observation left out, and y_i^* is a posterior prediction of the ith observation, then the LOO-PIT value for the ith observation is defined as\n\nP(y_i^* le y_i mid y_-i) = int_-infty^y_i p(y_i^* mid y_-i) mathrmd y_i^*\n\nThe LOO posterior predictions and the corresponding observations should have similar distributions, so if conditional predictive distributions are well-calibrated, then all LOO-PIT values should be approximately uniformly distributed on 0 1.[Gabry2019]\n\n[Gabry2019]: Gabry, J., Simpson, D., Vehtari, A., Betancourt, M. & Gelman, A. Visualization in Bayesian Workflow. J. R. Stat. Soc. Ser. A Stat. Soc. 182, 389–402 (2019). doi: 10.1111/rssa.12378 arXiv: 1709.01449\n\nExamples\n\nCalculate LOO-PIT values using as test quantity the observed values themselves.\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> log_weights = loo(idata; var_name=:obs).psis_result.log_weights;\n\njulia> loo_pit(\n            idata.observed_data.obs,\n            permutedims(idata.posterior_predictive.obs, (:draw, :chain, :school)),\n            log_weights,\n        )\n8-element DimArray{Float64,1} with dimensions:\n  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul's, Mt. Hermon] Unordered\n \"Choate\"            0.943511\n \"Deerfield\"         0.63797\n \"Phillips Andover\"  0.316697\n \"Phillips Exeter\"   0.582252\n \"Hotchkiss\"         0.295321\n \"Lawrenceville\"     0.403318\n \"St. Paul's\"        0.902508\n \"Mt. Hermon\"        0.655275\n\nCalculate LOO-PIT values using as test quantity the square of the difference between each observation and mu.\n\njulia> using DimensionalData, Statistics\n\njulia> T = idata.observed_data.obs .- only(median(idata.posterior.mu; dims=(:draw, :chain)));\n\njulia> T_pred = permutedims(\n           broadcast_dims(-, idata.posterior_predictive.obs, idata.posterior.mu),\n           (:draw, :chain, :school),\n       );\n\njulia> loo_pit(T .^ 2, T_pred .^ 2, log_weights)\n8-element DimArray{Float64,1} with dimensions:\n  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul's, Mt. Hermon] Unordered\n \"Choate\"            0.873577\n \"Deerfield\"         0.243686\n \"Phillips Andover\"  0.357563\n \"Phillips Exeter\"   0.149908\n \"Hotchkiss\"         0.435094\n \"Lawrenceville\"     0.220627\n \"St. Paul's\"        0.775086\n \"Mt. Hermon\"        0.296706\n\n\n\n\n\nloo_pit(idata::InferenceData, log_weights; kwargs...) -> DimArray\n\nCompute LOO-PIT values using existing normalized log LOO importance weights.\n\nKeywords\n\ny_name: Name of observed data variable in idata.observed_data. If not provided, then the only observed data variable is used.\ny_pred_name: Name of posterior predictive variable in idata.posterior_predictive. If not provided, then y_name is used.\nkwargs: Remaining keywords are forwarded to loo_pit.\n\nExamples\n\nCalculate LOO-PIT values using already computed log weights.\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> loo_result = loo(idata; var_name=:obs);\n\njulia> loo_pit(idata, loo_result.psis_result.log_weights; y_name=:obs)\n8-element DimArray{Float64,1} loo_pit_obs with dimensions:\n  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul's, Mt. Hermon] Unordered\n \"Choate\"            0.943511\n \"Deerfield\"         0.63797\n \"Phillips Andover\"  0.316697\n \"Phillips Exeter\"   0.582252\n \"Hotchkiss\"         0.295321\n \"Lawrenceville\"     0.403318\n \"St. Paul's\"        0.902508\n \"Mt. Hermon\"        0.655275\n\n\n\n\n\nloo_pit(idata::InferenceData; kwargs...) -> DimArray\n\nCompute LOO-PIT from groups in idata using PSIS-LOO.\n\nSee also: loo, PSIS.psis\n\nKeywords\n\ny_name: Name of observed data variable in idata.observed_data. If not provided, then the only observed data variable is used.\ny_pred_name: Name of posterior predictive variable in idata.posterior_predictive. If not provided, then y_name is used.\nlog_likelihood_name: Name of log-likelihood variable in idata.log_likelihood. If not provided, then y_name is used if idata has a log_likelihood group, otherwise the only variable is used.\nreff::Union{Real,AbstractArray{<:Real}}: The relative effective sample size(s) of the likelihood values. If an array, it must have the same data dimensions as the corresponding log-likelihood variable. If not provided, then this is estimated using MCMCDiagnosticTools.ess.\nkwargs: Remaining keywords are forwarded to loo_pit.\n\nExamples\n\nCalculate LOO-PIT values using as test quantity the observed values themselves.\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> loo_pit(idata; y_name=:obs)\n8-element DimArray{Float64,1} loo_pit_obs with dimensions:\n  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul's, Mt. Hermon] Unordered\n \"Choate\"            0.943511\n \"Deerfield\"         0.63797\n \"Phillips Andover\"  0.316697\n \"Phillips Exeter\"   0.582252\n \"Hotchkiss\"         0.295321\n \"Lawrenceville\"     0.403318\n \"St. Paul's\"        0.902508\n \"Mt. Hermon\"        0.655275\n\n\n\n\n\n","category":"function"},{"location":"api/#Utilities","page":"API","title":"Utilities","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"PosteriorStats.smooth_data","category":"page"},{"location":"api/#PosteriorStats.smooth_data","page":"API","title":"PosteriorStats.smooth_data","text":"smooth_data(y; dims=:, interp_method=CubicSpline, offset_frac=0.01)\n\nSmooth y along dims using interp_method.\n\ninterp_method is a 2-argument callabale that takes the arguments y and x and returns a DataInterpolations.jl interpolation method, defaulting to a cubic spline interpolator.\n\noffset_frac is the fraction of the length of y to use as an offset when interpolating.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = PosteriorStats","category":"page"},{"location":"#PosteriorStats","page":"Home","title":"PosteriorStats","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for PosteriorStats.","category":"page"}]
}
